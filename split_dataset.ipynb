{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7878209d-14fb-49ee-901c-5dff9a8970fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from collections import Counter, defaultdict\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecc134db-a1ee-464a-8fd1-e4a6203376bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample num : 206 | patient num : 48\n",
      "(206, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Slide_name</th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Recurrence</th>\n",
       "      <th>Location</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>Growth phase</th>\n",
       "      <th>Size of tumor</th>\n",
       "      <th>Depth of invasion</th>\n",
       "      <th>Level of invasion</th>\n",
       "      <th>Mitosis</th>\n",
       "      <th>Histologic subtype</th>\n",
       "      <th>Tumor cell type</th>\n",
       "      <th>Surgical margin</th>\n",
       "      <th>Lymph node</th>\n",
       "      <th>Breslow thickness</th>\n",
       "      <th>Precursor lesion</th>\n",
       "      <th>Date_of_diagnosis</th>\n",
       "      <th>Date_of_recurrence</th>\n",
       "      <th>recurrence_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>train_789</td>\n",
       "      <td>train_pid_194</td>\n",
       "      <td>1</td>\n",
       "      <td>plantar</td>\n",
       "      <td>MALIGNANT MELANOMA, INVASIVE</td>\n",
       "      <td>vertical</td>\n",
       "      <td>7.5 x 5.5 x 0.9 cm</td>\n",
       "      <td>8 mm</td>\n",
       "      <td>invasion into the subcutaneous fat (level 5)</td>\n",
       "      <td>16/10HPF</td>\n",
       "      <td>acral lentiginous</td>\n",
       "      <td>epithelioid</td>\n",
       "      <td>free from tumor (safety margin: anterior, 0.1 ...</td>\n",
       "      <td>cannot be assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-05</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>train_776</td>\n",
       "      <td>train_pid_191</td>\n",
       "      <td>1</td>\n",
       "      <td>big toe</td>\n",
       "      <td>MALIGNANT MELANOMA, invasive</td>\n",
       "      <td>radial</td>\n",
       "      <td>1.2 x 0.6 x 0.1cm</td>\n",
       "      <td>1mm</td>\n",
       "      <td>invasion to papillary dermis (level III)</td>\n",
       "      <td>2/10 HPF</td>\n",
       "      <td>acral lentiginous</td>\n",
       "      <td>epithelioid</td>\n",
       "      <td>free from tumor (safety margin: proximal, 0.2c...</td>\n",
       "      <td>cannot be assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27</td>\n",
       "      <td>2022-11-29</td>\n",
       "      <td>3807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>train_855</td>\n",
       "      <td>train_pid_206</td>\n",
       "      <td>1</td>\n",
       "      <td>thumb</td>\n",
       "      <td>MALIGNANT MELANOMA, INVASIVE</td>\n",
       "      <td>vertical</td>\n",
       "      <td>1.6 x 0.9 x 0.5 cm</td>\n",
       "      <td>5 mm</td>\n",
       "      <td>invasion into the subcutaneous fat (level 5)</td>\n",
       "      <td>20/10 HPF</td>\n",
       "      <td>acral lentiginous</td>\n",
       "      <td>epithelioid and spindle</td>\n",
       "      <td>free from tumor (safety margin: proximal, 1.2 cm)</td>\n",
       "      <td>no metastatis in two lymph nodes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-01-19</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>train_739</td>\n",
       "      <td>train_pid_180</td>\n",
       "      <td>1</td>\n",
       "      <td>finger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>2014-08-19</td>\n",
       "      <td>2198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>train_833</td>\n",
       "      <td>train_pid_201</td>\n",
       "      <td>1</td>\n",
       "      <td>foot</td>\n",
       "      <td>MALIGNANT MELANOMA, INVASIVE</td>\n",
       "      <td>vertical</td>\n",
       "      <td>2.5 x 2.1 x 1.1 cm</td>\n",
       "      <td>11 mm</td>\n",
       "      <td>invasion into the subcutaneous fat (level 5)</td>\n",
       "      <td>24/10HPF</td>\n",
       "      <td>acral lentiginous</td>\n",
       "      <td>spindle and epithelioid</td>\n",
       "      <td>free from tumor (safety margin: anterior, 2.1 ...</td>\n",
       "      <td>cannot be assessed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-13</td>\n",
       "      <td>2016-02-24</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Slide_name     Patient_ID  Recurrence Location  \\\n",
       "100  train_789  train_pid_194           1  plantar   \n",
       "87   train_776  train_pid_191           1  big toe   \n",
       "166  train_855  train_pid_206           1    thumb   \n",
       "50   train_739  train_pid_180           1   finger   \n",
       "144  train_833  train_pid_201           1     foot   \n",
       "\n",
       "                        Diagnosis Growth phase       Size of tumor  \\\n",
       "100  MALIGNANT MELANOMA, INVASIVE     vertical  7.5 x 5.5 x 0.9 cm   \n",
       "87   MALIGNANT MELANOMA, invasive       radial   1.2 x 0.6 x 0.1cm   \n",
       "166  MALIGNANT MELANOMA, INVASIVE     vertical  1.6 x 0.9 x 0.5 cm   \n",
       "50                            NaN          NaN                 NaN   \n",
       "144  MALIGNANT MELANOMA, INVASIVE     vertical  2.5 x 2.1 x 1.1 cm   \n",
       "\n",
       "    Depth of invasion                             Level of invasion  \\\n",
       "100              8 mm  invasion into the subcutaneous fat (level 5)   \n",
       "87                1mm      invasion to papillary dermis (level III)   \n",
       "166              5 mm  invasion into the subcutaneous fat (level 5)   \n",
       "50                NaN                                           NaN   \n",
       "144             11 mm  invasion into the subcutaneous fat (level 5)   \n",
       "\n",
       "       Mitosis Histologic subtype          Tumor cell type  \\\n",
       "100   16/10HPF  acral lentiginous              epithelioid   \n",
       "87    2/10 HPF  acral lentiginous              epithelioid   \n",
       "166  20/10 HPF  acral lentiginous  epithelioid and spindle   \n",
       "50         NaN                NaN                      NaN   \n",
       "144   24/10HPF  acral lentiginous  spindle and epithelioid   \n",
       "\n",
       "                                       Surgical margin  \\\n",
       "100  free from tumor (safety margin: anterior, 0.1 ...   \n",
       "87   free from tumor (safety margin: proximal, 0.2c...   \n",
       "166  free from tumor (safety margin: proximal, 1.2 cm)   \n",
       "50                                                 NaN   \n",
       "144  free from tumor (safety margin: anterior, 2.1 ...   \n",
       "\n",
       "                           Lymph node Breslow thickness Precursor lesion  \\\n",
       "100                cannot be assessed               NaN              NaN   \n",
       "87                 cannot be assessed               NaN              NaN   \n",
       "166  no metastatis in two lymph nodes               NaN              NaN   \n",
       "50                                NaN               NaN              NaN   \n",
       "144                cannot be assessed               NaN              NaN   \n",
       "\n",
       "    Date_of_diagnosis Date_of_recurrence  recurrence_period  \n",
       "100        2015-02-05         2015-05-13                 97  \n",
       "87         2012-06-27         2022-11-29               3807  \n",
       "166        2017-01-19         2018-10-26                645  \n",
       "50         2008-08-12         2014-08-19               2198  \n",
       "144        2015-01-13         2016-02-24                407  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './train_dataset_recurrent.csv' # './train_dataset_nonrecurrent.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"sample num : %d | patient num : %d\" %(len(df), len(df['Patient_ID'].value_counts())))\n",
    "print(df.shape)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0329be16-33b6-460d-8f26-24c4ea91a3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'patient ID count'}, xlabel='Patient_ID', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df['Patient_ID'].value_counts()\n",
    "df['Patient_ID'].value_counts().plot(kind=\"bar\", title=\"patient ID count\", ylabel='count', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c11fcbbd-04fb-4bcd-b73d-1f331aa1a8ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['psudo_label'] = df.Location.map({c: idx for idx, c in enumerate(df.Location.unique())})\n",
    "# df.sample(20)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9796d953-ce68-4bc2-b448-1e1bc2ed764d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location\n",
      "foot           39\n",
      "big toe        35\n",
      "finger         32\n",
      "sole           30\n",
      "toe            24\n",
      "heel           16\n",
      "thumb          14\n",
      "plantar         8\n",
      "palm            6\n",
      "hand            1\n",
      "foot dorsum     1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "psudo_label\n",
      "4     39\n",
      "1     35\n",
      "3     32\n",
      "7     30\n",
      "2     24\n",
      "5     16\n",
      "0     14\n",
      "9      8\n",
      "6      6\n",
      "8      1\n",
      "10     1\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df['Location'].value_counts())\n",
    "print()\n",
    "print(df['psudo_label'].value_counts())\n",
    "print()\n",
    "\n",
    "# ankle only in nonrecurrent (9)\n",
    "# foor dorsum only in recurrent (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cd01b36-afb7-4738-8d2e-01639a3554a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df\n",
    "Y = df.psudo_label.values # df['Location'].values\n",
    "groups = np.array(df['Patient_ID'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a44cac-b44c-4963-a8f7-71e874638900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_distribution(y_vals):\n",
    "    y_distr = Counter(y_vals)\n",
    "    y_vals_sum = sum(y_distr.values())\n",
    "    # print(np.max(y_vals))\n",
    "    return [f'{y_distr[i] / y_vals_sum:.2%}' for i in range(np.max(y_vals) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b73c065-0e72-43aa-bdbf-889883bad801",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train_dataset_recurrent.csv\n",
      "./recurrent_split_train_val\n"
     ]
    }
   ],
   "source": [
    "fold_root = f\"./{file_path.split('_')[-1][:-4]}_split_train_val\"\n",
    "print(file_path)\n",
    "print(fold_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a53eaee7-1409-4a37-a3d2-9356dca41706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "# train : 159 (0.77) | val : 47 (0.23)\n",
      "Fold 0:\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "# train : 163 (0.79) | val : 43 (0.21)\n",
      "Fold 1:\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "# train : 166 (0.81) | val : 40 (0.19)\n",
      "Fold 2:\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "# train : 167 (0.81) | val : 39 (0.19)\n",
      "Fold 3:\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'pandas.core.frame.DataFrame'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "# train : 169 (0.82) | val : 37 (0.18)\n",
      "Fold 4:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch-maic2023/lib/python3.9/site-packages/sklearn/model_selection/_split.py:950: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Distribution per class:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0</th>\n",
       "      <th>Label 1</th>\n",
       "      <th>Label 2</th>\n",
       "      <th>Label 3</th>\n",
       "      <th>Label 4</th>\n",
       "      <th>Label 5</th>\n",
       "      <th>Label 6</th>\n",
       "      <th>Label 7</th>\n",
       "      <th>Label 8</th>\n",
       "      <th>Label 9</th>\n",
       "      <th>Label 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training set</th>\n",
       "      <td>6.80%</td>\n",
       "      <td>16.99%</td>\n",
       "      <td>11.65%</td>\n",
       "      <td>15.53%</td>\n",
       "      <td>18.93%</td>\n",
       "      <td>7.77%</td>\n",
       "      <td>2.91%</td>\n",
       "      <td>14.56%</td>\n",
       "      <td>0.49%</td>\n",
       "      <td>3.88%</td>\n",
       "      <td>0.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 0</th>\n",
       "      <td>3.77%</td>\n",
       "      <td>18.87%</td>\n",
       "      <td>11.95%</td>\n",
       "      <td>16.35%</td>\n",
       "      <td>21.38%</td>\n",
       "      <td>7.55%</td>\n",
       "      <td>3.77%</td>\n",
       "      <td>10.06%</td>\n",
       "      <td>0.63%</td>\n",
       "      <td>5.03%</td>\n",
       "      <td>0.63%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 0</th>\n",
       "      <td>17.02%</td>\n",
       "      <td>10.64%</td>\n",
       "      <td>10.64%</td>\n",
       "      <td>12.77%</td>\n",
       "      <td>10.64%</td>\n",
       "      <td>8.51%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>29.79%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 1</th>\n",
       "      <td>5.52%</td>\n",
       "      <td>17.79%</td>\n",
       "      <td>11.66%</td>\n",
       "      <td>16.56%</td>\n",
       "      <td>17.18%</td>\n",
       "      <td>9.20%</td>\n",
       "      <td>3.68%</td>\n",
       "      <td>17.18%</td>\n",
       "      <td>0.61%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 1</th>\n",
       "      <td>11.63%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>11.63%</td>\n",
       "      <td>25.58%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>18.60%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 2</th>\n",
       "      <td>8.43%</td>\n",
       "      <td>15.06%</td>\n",
       "      <td>11.45%</td>\n",
       "      <td>16.27%</td>\n",
       "      <td>20.48%</td>\n",
       "      <td>8.43%</td>\n",
       "      <td>2.41%</td>\n",
       "      <td>12.65%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4.82%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 2</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>25.00%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>12.50%</td>\n",
       "      <td>5.00%</td>\n",
       "      <td>5.00%</td>\n",
       "      <td>22.50%</td>\n",
       "      <td>2.50%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.50%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 3</th>\n",
       "      <td>8.38%</td>\n",
       "      <td>15.57%</td>\n",
       "      <td>11.98%</td>\n",
       "      <td>13.77%</td>\n",
       "      <td>20.96%</td>\n",
       "      <td>5.99%</td>\n",
       "      <td>1.20%</td>\n",
       "      <td>16.17%</td>\n",
       "      <td>0.60%</td>\n",
       "      <td>4.79%</td>\n",
       "      <td>0.60%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 3</th>\n",
       "      <td>0.00%</td>\n",
       "      <td>23.08%</td>\n",
       "      <td>10.26%</td>\n",
       "      <td>23.08%</td>\n",
       "      <td>10.26%</td>\n",
       "      <td>15.38%</td>\n",
       "      <td>10.26%</td>\n",
       "      <td>7.69%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 4</th>\n",
       "      <td>7.69%</td>\n",
       "      <td>17.75%</td>\n",
       "      <td>11.24%</td>\n",
       "      <td>14.79%</td>\n",
       "      <td>14.79%</td>\n",
       "      <td>7.69%</td>\n",
       "      <td>3.55%</td>\n",
       "      <td>16.57%</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>4.73%</td>\n",
       "      <td>0.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 4</th>\n",
       "      <td>2.70%</td>\n",
       "      <td>13.51%</td>\n",
       "      <td>13.51%</td>\n",
       "      <td>18.92%</td>\n",
       "      <td>37.84%</td>\n",
       "      <td>8.11%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>5.41%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Label 0 Label 1 Label 2 Label 3 Label 4 Label 5  \\\n",
       "training set               6.80%  16.99%  11.65%  15.53%  18.93%   7.77%   \n",
       "development set - fold 0   3.77%  18.87%  11.95%  16.35%  21.38%   7.55%   \n",
       "validation set - fold 0   17.02%  10.64%  10.64%  12.77%  10.64%   8.51%   \n",
       "development set - fold 1   5.52%  17.79%  11.66%  16.56%  17.18%   9.20%   \n",
       "validation set - fold 1   11.63%  13.95%  11.63%  11.63%  25.58%   2.33%   \n",
       "development set - fold 2   8.43%  15.06%  11.45%  16.27%  20.48%   8.43%   \n",
       "validation set - fold 2    0.00%  25.00%  12.50%  12.50%  12.50%   5.00%   \n",
       "development set - fold 3   8.38%  15.57%  11.98%  13.77%  20.96%   5.99%   \n",
       "validation set - fold 3    0.00%  23.08%  10.26%  23.08%  10.26%  15.38%   \n",
       "development set - fold 4   7.69%  17.75%  11.24%  14.79%  14.79%   7.69%   \n",
       "validation set - fold 4    2.70%  13.51%  13.51%  18.92%  37.84%   8.11%   \n",
       "\n",
       "                         Label 6 Label 7 Label 8 Label 9 Label 10  \n",
       "training set               2.91%  14.56%   0.49%   3.88%    0.49%  \n",
       "development set - fold 0   3.77%  10.06%   0.63%   5.03%    0.63%  \n",
       "validation set - fold 0    0.00%  29.79%    None    None     None  \n",
       "development set - fold 1   3.68%  17.18%   0.61%   0.00%    0.61%  \n",
       "validation set - fold 1    0.00%   4.65%   0.00%  18.60%     None  \n",
       "development set - fold 2   2.41%  12.65%   0.00%   4.82%     None  \n",
       "validation set - fold 2    5.00%  22.50%   2.50%   0.00%    2.50%  \n",
       "development set - fold 3   1.20%  16.17%   0.60%   4.79%    0.60%  \n",
       "validation set - fold 3   10.26%   7.69%    None    None     None  \n",
       "development set - fold 4   3.55%  16.57%   0.59%   4.73%    0.59%  \n",
       "validation set - fold 4    0.00%   5.41%    None    None     None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row 생략 없이 출력\n",
    "pd.set_option('display.max_rows', None)\n",
    "# col 생략 없이 출력\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "distrs = [get_distribution(Y)]\n",
    "index = ['training set']\n",
    "cv = StratifiedGroupKFold(n_splits=5) # shuffle=True\n",
    "\n",
    "for fold_ind, (dev_ind, val_ind) in enumerate(cv.split(X, Y, groups)):\n",
    "    # print('# ', fold_ind, (dev_ind, val_ind))\n",
    "    dev_x, val_x = X.iloc[dev_ind], X.iloc[val_ind]\n",
    "    dev_y, val_y = Y[dev_ind], Y[val_ind]\n",
    "    dev_groups, val_groups = groups[dev_ind], groups[val_ind]\n",
    "    print(type(dev_x), type(val_x))\n",
    "    print(type(dev_y), type(val_y))\n",
    "    print(type(dev_groups), type(val_groups))\n",
    "    \n",
    "    # making sure that train and validation group do not overlap:\n",
    "    assert len(set(dev_groups) & set(val_groups)) == 0\n",
    "    print(f'# train : {len(dev_groups)} ({len(dev_groups)/len(groups):.2f}) | val : {len(val_groups)} ({len(val_groups)/len(groups):.2f})')\n",
    "    # print('## ', len(set(dev_groups)), len(set(val_groups)))\n",
    "    \n",
    "    print(f\"Fold {fold_ind}:\")\n",
    "    # print(f\"  Train: index={dev_ind}\")\n",
    "    # print(f\"         group={groups[dev_ind]}\")\n",
    "    # print(f\"  Test:  index={val_ind}\")\n",
    "    # print(f\"         group={groups[val_ind]}\")\n",
    "    \n",
    "    distrs.append(get_distribution(dev_y))\n",
    "    index.append(f'development set - fold {fold_ind}')\n",
    "    distrs.append(get_distribution(val_y))\n",
    "    index.append(f'validation set - fold {fold_ind}')\n",
    "    \n",
    "    # dev_x.to_csv(os.path.join(fold_root, f\"fold_{fold_ind}_train.csv\"), index=False)\n",
    "    # val_x.to_csv(os.path.join(fold_root, f\"fold_{fold_ind}_val.csv\"), index=False)\n",
    "\n",
    "display('Distribution per class:')\n",
    "pd.DataFrame(distrs, index=index, columns=[f'Label {l}' for l in range(np.max(Y) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "566f57c4-ab83-43ae-b24e-484c13e5e4de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_fold : 0 | fold_idx : 0\n",
      "val/test split_ratio :  2\n",
      "train : (345, 20) | val : (171, 20) | test : (172, 20)\n",
      " -> train : 0.50 | val : 0.25 | test : 0.25\n",
      "num_fold : 0 | fold_idx : 1\n",
      "val/test split_ratio :  2\n",
      "train : (343, 20) | val : (169, 20) | test : (176, 20)\n",
      " -> train : 0.50 | val : 0.25 | test : 0.26\n",
      "num_fold : 1 | fold_idx : 0\n",
      "val/test split_ratio :  2\n",
      "train : (341, 20) | val : (173, 20) | test : (174, 20)\n",
      " -> train : 0.50 | val : 0.25 | test : 0.25\n",
      "num_fold : 1 | fold_idx : 1\n",
      "val/test split_ratio :  2\n",
      "train : (347, 20) | val : (169, 20) | test : (172, 20)\n",
      " -> train : 0.50 | val : 0.25 | test : 0.25\n",
      "num_fold : 2 | fold_idx : 0\n",
      "val/test split_ratio :  2\n",
      "train : (315, 20) | val : (186, 20) | test : (187, 20)\n",
      " -> train : 0.46 | val : 0.27 | test : 0.27\n",
      "num_fold : 2 | fold_idx : 1\n",
      "val/test split_ratio :  2\n",
      "train : (373, 20) | val : (158, 20) | test : (157, 20)\n",
      " -> train : 0.54 | val : 0.23 | test : 0.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/torch-maic2023/lib/python3.9/site-packages/sklearn/model_selection/_split.py:950: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/torch-maic2023/lib/python3.9/site-packages/sklearn/model_selection/_split.py:950: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Distribution per class:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label 0</th>\n",
       "      <th>Label 1</th>\n",
       "      <th>Label 2</th>\n",
       "      <th>Label 3</th>\n",
       "      <th>Label 4</th>\n",
       "      <th>Label 5</th>\n",
       "      <th>Label 6</th>\n",
       "      <th>Label 7</th>\n",
       "      <th>Label 8</th>\n",
       "      <th>Label 9</th>\n",
       "      <th>Label 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>training set</th>\n",
       "      <td>12.65%</td>\n",
       "      <td>6.40%</td>\n",
       "      <td>10.03%</td>\n",
       "      <td>13.95%</td>\n",
       "      <td>25.00%</td>\n",
       "      <td>23.55%</td>\n",
       "      <td>4.51%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>0.87%</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>1.31%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 0</th>\n",
       "      <td>14.78%</td>\n",
       "      <td>6.38%</td>\n",
       "      <td>4.06%</td>\n",
       "      <td>12.46%</td>\n",
       "      <td>28.41%</td>\n",
       "      <td>24.93%</td>\n",
       "      <td>5.80%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.61%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 0</th>\n",
       "      <td>10.53%</td>\n",
       "      <td>6.43%</td>\n",
       "      <td>16.37%</td>\n",
       "      <td>15.79%</td>\n",
       "      <td>21.64%</td>\n",
       "      <td>22.22%</td>\n",
       "      <td>3.51%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>2.92%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test set - fold 0</th>\n",
       "      <td>10.47%</td>\n",
       "      <td>6.40%</td>\n",
       "      <td>15.70%</td>\n",
       "      <td>15.12%</td>\n",
       "      <td>21.51%</td>\n",
       "      <td>22.09%</td>\n",
       "      <td>2.91%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 1</th>\n",
       "      <td>10.50%</td>\n",
       "      <td>6.41%</td>\n",
       "      <td>16.03%</td>\n",
       "      <td>15.45%</td>\n",
       "      <td>21.57%</td>\n",
       "      <td>22.16%</td>\n",
       "      <td>3.21%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>1.75%</td>\n",
       "      <td>2.33%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 1</th>\n",
       "      <td>15.38%</td>\n",
       "      <td>6.51%</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>13.02%</td>\n",
       "      <td>28.99%</td>\n",
       "      <td>25.44%</td>\n",
       "      <td>5.92%</td>\n",
       "      <td>0.59%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test set - fold 1</th>\n",
       "      <td>14.20%</td>\n",
       "      <td>6.25%</td>\n",
       "      <td>3.98%</td>\n",
       "      <td>11.93%</td>\n",
       "      <td>27.84%</td>\n",
       "      <td>24.43%</td>\n",
       "      <td>5.68%</td>\n",
       "      <td>0.57%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>5.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 2</th>\n",
       "      <td>15.25%</td>\n",
       "      <td>4.69%</td>\n",
       "      <td>6.45%</td>\n",
       "      <td>16.42%</td>\n",
       "      <td>24.34%</td>\n",
       "      <td>25.81%</td>\n",
       "      <td>4.69%</td>\n",
       "      <td>0.88%</td>\n",
       "      <td>1.47%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 2</th>\n",
       "      <td>10.40%</td>\n",
       "      <td>7.51%</td>\n",
       "      <td>13.87%</td>\n",
       "      <td>11.56%</td>\n",
       "      <td>25.43%</td>\n",
       "      <td>21.39%</td>\n",
       "      <td>4.62%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>5.20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test set - fold 2</th>\n",
       "      <td>9.77%</td>\n",
       "      <td>8.62%</td>\n",
       "      <td>13.22%</td>\n",
       "      <td>11.49%</td>\n",
       "      <td>25.86%</td>\n",
       "      <td>21.26%</td>\n",
       "      <td>4.02%</td>\n",
       "      <td>0.57%</td>\n",
       "      <td>0.57%</td>\n",
       "      <td>4.60%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 3</th>\n",
       "      <td>10.09%</td>\n",
       "      <td>8.07%</td>\n",
       "      <td>13.54%</td>\n",
       "      <td>11.53%</td>\n",
       "      <td>25.65%</td>\n",
       "      <td>21.33%</td>\n",
       "      <td>4.32%</td>\n",
       "      <td>0.29%</td>\n",
       "      <td>0.29%</td>\n",
       "      <td>2.31%</td>\n",
       "      <td>2.59%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 3</th>\n",
       "      <td>15.38%</td>\n",
       "      <td>4.73%</td>\n",
       "      <td>6.51%</td>\n",
       "      <td>16.57%</td>\n",
       "      <td>24.85%</td>\n",
       "      <td>26.04%</td>\n",
       "      <td>4.73%</td>\n",
       "      <td>1.18%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test set - fold 3</th>\n",
       "      <td>15.12%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>6.40%</td>\n",
       "      <td>16.28%</td>\n",
       "      <td>23.84%</td>\n",
       "      <td>25.58%</td>\n",
       "      <td>4.65%</td>\n",
       "      <td>0.58%</td>\n",
       "      <td>2.91%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 4</th>\n",
       "      <td>16.51%</td>\n",
       "      <td>9.84%</td>\n",
       "      <td>8.89%</td>\n",
       "      <td>12.06%</td>\n",
       "      <td>25.40%</td>\n",
       "      <td>16.19%</td>\n",
       "      <td>4.76%</td>\n",
       "      <td>0.95%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.54%</td>\n",
       "      <td>2.86%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 4</th>\n",
       "      <td>9.68%</td>\n",
       "      <td>3.23%</td>\n",
       "      <td>10.75%</td>\n",
       "      <td>15.59%</td>\n",
       "      <td>24.73%</td>\n",
       "      <td>30.11%</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>0.54%</td>\n",
       "      <td>0.54%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test set - fold 4</th>\n",
       "      <td>9.09%</td>\n",
       "      <td>3.74%</td>\n",
       "      <td>11.23%</td>\n",
       "      <td>15.51%</td>\n",
       "      <td>24.60%</td>\n",
       "      <td>29.41%</td>\n",
       "      <td>3.74%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2.67%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>development set - fold 5</th>\n",
       "      <td>9.38%</td>\n",
       "      <td>3.49%</td>\n",
       "      <td>10.99%</td>\n",
       "      <td>15.55%</td>\n",
       "      <td>24.66%</td>\n",
       "      <td>29.76%</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation set - fold 5</th>\n",
       "      <td>15.82%</td>\n",
       "      <td>10.13%</td>\n",
       "      <td>8.86%</td>\n",
       "      <td>12.03%</td>\n",
       "      <td>25.32%</td>\n",
       "      <td>16.46%</td>\n",
       "      <td>5.06%</td>\n",
       "      <td>0.63%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>5.70%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test set - fold 5</th>\n",
       "      <td>17.20%</td>\n",
       "      <td>9.55%</td>\n",
       "      <td>8.92%</td>\n",
       "      <td>12.10%</td>\n",
       "      <td>25.48%</td>\n",
       "      <td>15.92%</td>\n",
       "      <td>4.46%</td>\n",
       "      <td>1.27%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>5.10%</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Label 0 Label 1 Label 2 Label 3 Label 4 Label 5  \\\n",
       "training set              12.65%   6.40%  10.03%  13.95%  25.00%  23.55%   \n",
       "development set - fold 0  14.78%   6.38%   4.06%  12.46%  28.41%  24.93%   \n",
       "validation set - fold 0   10.53%   6.43%  16.37%  15.79%  21.64%  22.22%   \n",
       "test set - fold 0         10.47%   6.40%  15.70%  15.12%  21.51%  22.09%   \n",
       "development set - fold 1  10.50%   6.41%  16.03%  15.45%  21.57%  22.16%   \n",
       "validation set - fold 1   15.38%   6.51%   4.14%  13.02%  28.99%  25.44%   \n",
       "test set - fold 1         14.20%   6.25%   3.98%  11.93%  27.84%  24.43%   \n",
       "development set - fold 2  15.25%   4.69%   6.45%  16.42%  24.34%  25.81%   \n",
       "validation set - fold 2   10.40%   7.51%  13.87%  11.56%  25.43%  21.39%   \n",
       "test set - fold 2          9.77%   8.62%  13.22%  11.49%  25.86%  21.26%   \n",
       "development set - fold 3  10.09%   8.07%  13.54%  11.53%  25.65%  21.33%   \n",
       "validation set - fold 3   15.38%   4.73%   6.51%  16.57%  24.85%  26.04%   \n",
       "test set - fold 3         15.12%   4.65%   6.40%  16.28%  23.84%  25.58%   \n",
       "development set - fold 4  16.51%   9.84%   8.89%  12.06%  25.40%  16.19%   \n",
       "validation set - fold 4    9.68%   3.23%  10.75%  15.59%  24.73%  30.11%   \n",
       "test set - fold 4          9.09%   3.74%  11.23%  15.51%  24.60%  29.41%   \n",
       "development set - fold 5   9.38%   3.49%  10.99%  15.55%  24.66%  29.76%   \n",
       "validation set - fold 5   15.82%  10.13%   8.86%  12.03%  25.32%  16.46%   \n",
       "test set - fold 5         17.20%   9.55%   8.92%  12.10%  25.48%  15.92%   \n",
       "\n",
       "                         Label 6 Label 7 Label 8 Label 9 Label 10  \n",
       "training set               4.51%   0.58%   0.87%   1.16%    1.31%  \n",
       "development set - fold 0   5.80%   0.58%   0.00%   0.00%    2.61%  \n",
       "validation set - fold 0    3.51%   0.58%   2.92%    None     None  \n",
       "test set - fold 0          2.91%   0.58%   0.58%   4.65%     None  \n",
       "development set - fold 1   3.21%   0.58%   1.75%   2.33%     None  \n",
       "validation set - fold 1    5.92%   0.59%    None    None     None  \n",
       "test set - fold 1          5.68%   0.57%   0.00%   0.00%    5.11%  \n",
       "development set - fold 2   4.69%   0.88%   1.47%    None     None  \n",
       "validation set - fold 2    4.62%   0.00%   0.00%   0.00%    5.20%  \n",
       "test set - fold 2          4.02%   0.57%   0.57%   4.60%     None  \n",
       "development set - fold 3   4.32%   0.29%   0.29%   2.31%    2.59%  \n",
       "validation set - fold 3    4.73%   1.18%    None    None     None  \n",
       "test set - fold 3          4.65%   0.58%   2.91%    None     None  \n",
       "development set - fold 4   4.76%   0.95%   0.00%   2.54%    2.86%  \n",
       "validation set - fold 4    4.84%   0.54%   0.54%    None     None  \n",
       "test set - fold 4          3.74%   0.00%   2.67%    None     None  \n",
       "development set - fold 5   4.29%   0.27%   1.61%    None     None  \n",
       "validation set - fold 5    5.06%   0.63%   0.00%   0.00%    5.70%  \n",
       "test set - fold 5          4.46%   1.27%   0.00%   5.10%     None  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # row 생략 없이 출력\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# # col 생략 없이 출력\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "# # set the ratios for train, validation, and test splits\n",
    "# train_ratio = 0.6 # 0.5\n",
    "# val_ratio = 0.2 # 0.1\n",
    "# test_ratio = 0.2 # 0.4\n",
    "\n",
    "# assert train_ratio >= 0.5, \"This code only works when train_ratio is the biggest\"\n",
    "\n",
    "# num_splits = int(1 / (val_ratio + test_ratio)) # 5\n",
    "\n",
    "# X = df\n",
    "# Y = df.psudo_label.values # df['Location'].values\n",
    "# groups = np.array(df['Patient_ID'].values)\n",
    "\n",
    "# distrs = [get_distribution(Y)]\n",
    "# index = ['training set']\n",
    "\n",
    "# num_folds = 3\n",
    "# count_fold = 0\n",
    "# for num_fold in range(num_folds):\n",
    "#     # We instantiate a new one every time since we control the number of folds ourselves\n",
    "#     sgkf = StratifiedGroupKFold(n_splits=num_splits, random_state=num_fold, shuffle=True)\n",
    "#     # print(num_fold, num_splits)\n",
    "#     for fold_idx, (train_indices, val_test_indices) in enumerate(sgkf.split(X, Y, groups)):\n",
    "#         # print(type(train_indices), type(val_test_indices))\n",
    "#         # print(train_indices, val_test_indices)\n",
    "#         print(f\"num_fold : {num_fold} | fold_idx : {fold_idx}\")\n",
    "#         X_train = X.iloc[train_indices] # X[train_indices]\n",
    "#         Y_train = Y[train_indices]\n",
    "#         groups_train = groups[train_indices]\n",
    "\n",
    "#         X_val_test = X.iloc[val_test_indices] # X[val_test_indices]\n",
    "#         Y_val_test = Y[val_test_indices]\n",
    "#         groups_val_test = groups[val_test_indices]\n",
    "\n",
    "#         # Now we have to split it based on the ratio between test and val\n",
    "#         split_ratio = test_ratio / val_ratio\n",
    "#         test_val_order = True\n",
    "#         if split_ratio < 1: # In this case we invert the ratio and the assignment of test-val / val-test\n",
    "#             test_val_order = False\n",
    "#             split_ratio = 1 / split_ratio\n",
    "\n",
    "#         split_ratio = int(split_ratio) + 1\n",
    "#         print(\"val/test split_ratio : \", split_ratio)\n",
    "#         sgkf2 = StratifiedGroupKFold(n_splits=split_ratio)\n",
    "#         i1, i2 = next(sgkf2.split(X_val_test, Y_val_test, groups_val_test))\n",
    "#         # print(i1, i2)\n",
    "#         if test_val_order:\n",
    "#             test_indices = i1\n",
    "#             val_indices = i2\n",
    "#         else:\n",
    "#             test_indices = i2\n",
    "#             val_indices = i1\n",
    "\n",
    "#         X_val = X_val_test.iloc[val_indices] # X_val_test[val_indices]\n",
    "#         Y_val = Y_val_test[val_indices]\n",
    "#         groups_val = groups_val_test[val_indices]\n",
    "\n",
    "#         X_test = X_val_test.iloc[test_indices] # X_val_test[test_indices]\n",
    "#         Y_test = Y_val_test[test_indices]\n",
    "#         groups_test = groups_val_test[test_indices]\n",
    "\n",
    "#         # print(\"train groups = \", np.unique(groups_train))\n",
    "#         # print(\"val groups = \", np.unique(groups_val))\n",
    "#         # print(\"test groups = \", np.unique(groups_test))\n",
    "#         # print(X_train.shape, X_val.shape, X_test.shape)\n",
    "#         print(f\"train : {X_train.shape} | val : {X_val.shape} | test : {X_test.shape}\")\n",
    "#         print(f\" -> train : {len(X_train)/len(X):.2f} | val : {len(X_val)/len(X):.2f} | test : {len(X_test)/len(X):.2f}\")\n",
    "        \n",
    "#         distrs.append(get_distribution(Y_train))\n",
    "#         index.append(f'development set - fold {count_fold}')\n",
    "#         distrs.append(get_distribution(Y_val))\n",
    "#         index.append(f'validation set - fold {count_fold}')\n",
    "#         distrs.append(get_distribution(Y_test))\n",
    "#         index.append(f'test set - fold {count_fold}')\n",
    "#         count_fold += 1\n",
    "\n",
    "#     # print()\n",
    "\n",
    "# display('Distribution per class:')\n",
    "# pd.DataFrame(distrs, index=index, columns=[f'Label {l}' for l in range(np.max(Y) + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13ef8c-f5ad-4f97-8c71-b89a69f74783",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch-maic2023]",
   "language": "python",
   "name": "conda-env-torch-maic2023-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
